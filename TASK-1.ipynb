{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "475fc1b4",
   "metadata": {},
   "source": [
    "### 1. Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64a85fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done building\n",
      "?(X1 <= -1.1939721441501923)\n",
      "    Y: Prediction: 2.720169166589619\n",
      "    N: ?(X4 <= 0.3865751136808898)\n",
      "        Y: ?(X0 <= 1.5077915869695468)\n",
      "            Y: ?(X4 <= -1.7439789939378834)\n",
      "                Y: ?(X1 <= 0.8125418173520702)\n",
      "                    Y: Prediction: 0.534667267785164\n",
      "                    N: Prediction: 0.9633761292443218\n",
      "                N: ?(X2 <= 1.24071347131677)\n",
      "                    Y: Prediction: -0.345994377277823\n",
      "                    N: Prediction: 0.82206015999449\n",
      "            N: ?(X0 <= 1.870195015413759)\n",
      "                Y: Prediction: 1.4535340771573169\n",
      "                N: Prediction: 0.8271832490360238\n",
      "        N: ?(X0 <= -0.35665559739723524)\n",
      "            Y: ?(X0 <= -0.4904656407149133)\n",
      "                Y: ?(X0 <= -0.5517318279069667)\n",
      "                    Y: Prediction: 1.8657745111447566\n",
      "                    N: Prediction: 1.8967929826539474\n",
      "                N: Prediction: 1.158595579007404\n",
      "            N: ?(X4 <= 1.003272324809155)\n",
      "                Y: ?(X0 <= 0.8611560330796227)\n",
      "                    Y: Prediction: 0.3214303278812129\n",
      "                    N: Prediction: 0.787084603742452\n",
      "                N: Prediction: -0.9746816702273214\n",
      "Criteria : information_gain\n",
      "RMSE:  0.3601329774475513\n",
      "MAE:  0.24067253750418452\n",
      "done building\n",
      "?(X1 <= -1.1939721441501923)\n",
      "    Y: Prediction: 2.720169166589619\n",
      "    N: ?(X4 <= 0.3865751136808898)\n",
      "        Y: ?(X0 <= 1.5077915869695468)\n",
      "            Y: ?(X4 <= -1.7439789939378834)\n",
      "                Y: ?(X1 <= 0.8125418173520702)\n",
      "                    Y: Prediction: 0.534667267785164\n",
      "                    N: Prediction: 0.9633761292443218\n",
      "                N: ?(X2 <= 1.24071347131677)\n",
      "                    Y: Prediction: -0.345994377277823\n",
      "                    N: Prediction: 0.82206015999449\n",
      "            N: ?(X0 <= 1.870195015413759)\n",
      "                Y: Prediction: 1.4535340771573169\n",
      "                N: Prediction: 0.8271832490360238\n",
      "        N: ?(X0 <= -0.35665559739723524)\n",
      "            Y: ?(X0 <= -0.4904656407149133)\n",
      "                Y: ?(X0 <= -0.5517318279069667)\n",
      "                    Y: Prediction: 1.8657745111447566\n",
      "                    N: Prediction: 1.8967929826539474\n",
      "                N: Prediction: 1.158595579007404\n",
      "            N: ?(X4 <= 1.003272324809155)\n",
      "                Y: ?(X0 <= 0.8611560330796227)\n",
      "                    Y: Prediction: 0.3214303278812129\n",
      "                    N: Prediction: 0.787084603742452\n",
      "                N: Prediction: -0.9746816702273214\n",
      "Criteria : gini_index\n",
      "RMSE:  0.3601329774475513\n",
      "MAE:  0.24067253750418452\n",
      "done building\n",
      "?(X0 <= 0.5164969924782189)\n",
      "    Y: ?(X1 <= 1.0083193995209832)\n",
      "        Y: ?(X2 <= -0.7357749579035922)\n",
      "            Y: ?(X0 <= -0.41496725329268236)\n",
      "                Y: Prediction: None\n",
      "                N: Prediction: 2\n",
      "            N: ?(X4 <= 2.9983377899900234)\n",
      "                Y: ?(X2 <= -0.13234745834482112)\n",
      "                    Y: Prediction: 1\n",
      "                    N: Prediction: 1\n",
      "                N: Prediction: 4\n",
      "        N: ?(X2 <= -0.6496204272273054)\n",
      "            Y: ?(X0 <= -0.8660086274155504)\n",
      "                Y: Prediction: 4\n",
      "                N: Prediction: 3\n",
      "            N: Prediction: 4\n",
      "    N: ?(X1 <= -1.9462038896246776)\n",
      "        Y: Prediction: 3\n",
      "        N: ?(X4 <= -0.7267202584186923)\n",
      "            Y: Prediction: 4\n",
      "            N: ?(X0 <= 0.9239599087303167)\n",
      "                Y: ?(X0 <= 0.5982789292290867)\n",
      "                    Y: Prediction: 2\n",
      "                    N: Prediction: 4\n",
      "                N: Prediction: 2\n",
      "Criteria : information_gain\n",
      "Accuracy:  0.8666666666666667\n",
      "Precision:  1.0\n",
      "Recall:  0.9\n",
      "Precision:  0.7142857142857143\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  0.8\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  0.3333333333333333\n",
      "done building\n",
      "?(X0 <= 0.5164969924782189)\n",
      "    Y: ?(X1 <= 1.0083193995209832)\n",
      "        Y: ?(X2 <= -0.7357749579035922)\n",
      "            Y: ?(X0 <= -0.41496725329268236)\n",
      "                Y: Prediction: None\n",
      "                N: Prediction: 2\n",
      "            N: ?(X4 <= 2.9983377899900234)\n",
      "                Y: ?(X2 <= -0.13234745834482112)\n",
      "                    Y: Prediction: 1\n",
      "                    N: Prediction: 1\n",
      "                N: Prediction: 4\n",
      "        N: ?(X2 <= -0.6496204272273054)\n",
      "            Y: ?(X0 <= -0.8660086274155504)\n",
      "                Y: Prediction: 4\n",
      "                N: Prediction: 3\n",
      "            N: Prediction: 4\n",
      "    N: ?(X1 <= -1.9462038896246776)\n",
      "        Y: Prediction: 3\n",
      "        N: ?(X4 <= -0.7267202584186923)\n",
      "            Y: Prediction: 4\n",
      "            N: ?(X0 <= 0.9239599087303167)\n",
      "                Y: ?(X0 <= 0.5982789292290867)\n",
      "                    Y: Prediction: 2\n",
      "                    N: Prediction: 4\n",
      "                N: Prediction: 2\n",
      "Criteria : gini_index\n",
      "Accuracy:  0.8666666666666667\n",
      "Precision:  1.0\n",
      "Recall:  0.9\n",
      "Precision:  0.7142857142857143\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  0.8\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "Precision:  1.0\n",
      "Recall:  0.3333333333333333\n",
      "done building\n",
      "?(X1_4 <= 0.5)\n",
      "    Y: ?(X1_0 <= 0.5)\n",
      "        Y: ?(X4_3 <= 1.0)\n",
      "            Y: ?(X0_1 <= 0.5)\n",
      "                Y: ?(X0_3 <= 0.5)\n",
      "                    Y: Prediction: None\n",
      "                    N: Prediction: 2\n",
      "                N: Prediction: 2\n",
      "            N: ?(X0_1 <= 0.5)\n",
      "                Y: Prediction: 1\n",
      "                N: Prediction: 3\n",
      "        N: ?(X4_1 <= 0.5)\n",
      "            Y: ?(X0_2 <= 0.5)\n",
      "                Y: ?(X0_3 <= 0.5)\n",
      "                    Y: Prediction: 4\n",
      "                    N: Prediction: None\n",
      "                N: Prediction: None\n",
      "            N: Prediction: None\n",
      "    N: ?(X2_3 <= 0.5)\n",
      "        Y: ?(X0_4 <= 0.5)\n",
      "            Y: Prediction: 3\n",
      "            N: Prediction: 1\n",
      "        N: Prediction: 1\n",
      "Criteria : information_gain\n",
      "Accuracy:  0.3\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "Precision:  0.3\n",
      "Recall:  1.0\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "done building\n",
      "?(X1_4 <= 0.5)\n",
      "    Y: ?(X1_0 <= 0.5)\n",
      "        Y: ?(X4_3 <= 1.0)\n",
      "            Y: ?(X0_1 <= 0.5)\n",
      "                Y: ?(X0_3 <= 0.5)\n",
      "                    Y: Prediction: None\n",
      "                    N: Prediction: 2\n",
      "                N: Prediction: 2\n",
      "            N: ?(X0_1 <= 0.5)\n",
      "                Y: Prediction: 1\n",
      "                N: Prediction: 3\n",
      "        N: ?(X4_1 <= 0.5)\n",
      "            Y: ?(X0_2 <= 0.5)\n",
      "                Y: ?(X0_3 <= 0.5)\n",
      "                    Y: Prediction: 4\n",
      "                    N: Prediction: None\n",
      "                N: Prediction: None\n",
      "            N: Prediction: None\n",
      "    N: ?(X2_3 <= 0.5)\n",
      "        Y: ?(X0_4 <= 0.5)\n",
      "            Y: Prediction: 3\n",
      "            N: Prediction: 1\n",
      "        N: Prediction: 1\n",
      "Criteria : gini_index\n",
      "Accuracy:  0.3\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "Precision:  0.3\n",
      "Recall:  1.0\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "Precision:  0.0\n",
      "Recall:  0.0\n",
      "done building\n",
      "?(X2_1 <= 0.5)\n",
      "    Y: ?(X1_4 <= 0.5)\n",
      "        Y: ?(X3_0 <= 0.5)\n",
      "            Y: ?(X0_4 <= 0.5)\n",
      "                Y: ?(X4_0 <= 0.5)\n",
      "                    Y: Prediction: -0.04230933716632788\n",
      "                    N: Prediction: 1.2012139221639448\n",
      "                N: ?(X3_1 <= 0.5)\n",
      "                    Y: Prediction: -0.8751331298825052\n",
      "                    N: Prediction: -0.32602353216784113\n",
      "            N: ?(X2_2 <= 0.5)\n",
      "                Y: ?(X1_1 <= 0.5)\n",
      "                    Y: Prediction: 0.6055516824464391\n",
      "                    N: Prediction: 1.4415686206579004\n",
      "                N: Prediction: -0.5768918695231487\n",
      "        N: ?(X2_2 <= 0.5)\n",
      "            Y: Prediction: 2.075400798645439\n",
      "            N: ?(X0_2 <= 0.5)\n",
      "                Y: ?(X0_1 <= 0.5)\n",
      "                    Y: Prediction: 1.0062928092144405\n",
      "                    N: Prediction: 0.8356921120651418\n",
      "                N: Prediction: -0.2030453860429927\n",
      "    N: ?(X1_1 <= 0.5)\n",
      "        Y: ?(X0_1 <= 0.5)\n",
      "            Y: ?(X1_0 <= 0.5)\n",
      "                Y: ?(X0_2 <= 0.5)\n",
      "                    Y: Prediction: 0.8711247034316923\n",
      "                    N: Prediction: 0.3376026620752022\n",
      "                N: ?(X0_2 <= 0.5)\n",
      "                    Y: Prediction: -0.15567723539207948\n",
      "                    N: Prediction: -0.7968952554704768\n",
      "            N: Prediction: -2.038124535177854\n",
      "        N: Prediction: -2.4716445001272893\n",
      "Criteria : information_gain\n",
      "RMSE:  0.9632792025401334\n",
      "MAE:  0.7637039798826147\n",
      "done building\n",
      "?(X2_1 <= 0.5)\n",
      "    Y: ?(X1_4 <= 0.5)\n",
      "        Y: ?(X3_0 <= 0.5)\n",
      "            Y: ?(X0_4 <= 0.5)\n",
      "                Y: ?(X4_0 <= 0.5)\n",
      "                    Y: Prediction: -0.04230933716632788\n",
      "                    N: Prediction: 1.2012139221639448\n",
      "                N: ?(X3_1 <= 0.5)\n",
      "                    Y: Prediction: -0.8751331298825052\n",
      "                    N: Prediction: -0.32602353216784113\n",
      "            N: ?(X2_2 <= 0.5)\n",
      "                Y: ?(X1_1 <= 0.5)\n",
      "                    Y: Prediction: 0.6055516824464391\n",
      "                    N: Prediction: 1.4415686206579004\n",
      "                N: Prediction: -0.5768918695231487\n",
      "        N: ?(X2_2 <= 0.5)\n",
      "            Y: Prediction: 2.075400798645439\n",
      "            N: ?(X0_2 <= 0.5)\n",
      "                Y: ?(X0_1 <= 0.5)\n",
      "                    Y: Prediction: 1.0062928092144405\n",
      "                    N: Prediction: 0.8356921120651418\n",
      "                N: Prediction: -0.2030453860429927\n",
      "    N: ?(X1_1 <= 0.5)\n",
      "        Y: ?(X0_1 <= 0.5)\n",
      "            Y: ?(X1_0 <= 0.5)\n",
      "                Y: ?(X0_2 <= 0.5)\n",
      "                    Y: Prediction: 0.8711247034316923\n",
      "                    N: Prediction: 0.3376026620752022\n",
      "                N: ?(X0_2 <= 0.5)\n",
      "                    Y: Prediction: -0.15567723539207948\n",
      "                    N: Prediction: -0.7968952554704768\n",
      "            N: Prediction: -2.038124535177854\n",
      "        N: Prediction: -2.4716445001272893\n",
      "Criteria : gini_index\n",
      "RMSE:  0.9632792025401334\n",
      "MAE:  0.7637039798826147\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The current code given is for the Assignment 1.\n",
    "You will be expected to use this to make trees for:\n",
    "> discrete input, discrete output\n",
    "> real input, real output\n",
    "> real input, discrete output\n",
    "> discrete input, real output\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tree.base import DecisionTree\n",
    "from metrics import *\n",
    "\n",
    "np.random.seed(42)\n",
    "# Test case 1\n",
    "# Real Input and Real Output\n",
    "\n",
    "N = 30\n",
    "P = 5\n",
    "X = pd.DataFrame(np.random.randn(N, P))\n",
    "y = pd.Series(np.random.randn(N))\n",
    "\n",
    "\n",
    "for criteria in [\"information_gain\", \"gini_index\"]:\n",
    "    tree = DecisionTree(criterion=criteria)  # Split based on Inf. Gain\n",
    "    tree.fit(X, y)\n",
    "    y_hat = tree.predict(X)\n",
    "    tree.plot()\n",
    "    print(\"Criteria :\", criteria)\n",
    "    print(\"RMSE: \", rmse(y_hat, y))\n",
    "    print(\"MAE: \", mae(y_hat, y))\n",
    "\n",
    "# # Test case 2\n",
    "# # Real Input and Discrete Output\n",
    "\n",
    "N = 30\n",
    "P = 5\n",
    "X = pd.DataFrame(np.random.randn(N, P))\n",
    "y = pd.Series(np.random.randint(P, size=N), dtype=\"category\")\n",
    "\n",
    "for criteria in [\"information_gain\", \"gini_index\"]:\n",
    "    tree = DecisionTree(criterion=criteria)  # Split based on Inf. Gain\n",
    "    tree.fit(X, y)\n",
    "    y_hat = tree.predict(X)\n",
    "    tree.plot()\n",
    "    print(\"Criteria :\", criteria)\n",
    "    print(\"Accuracy: \", accuracy(y_hat, y))\n",
    "    for cls in y.unique():\n",
    "        print(\"Precision: \", precision(y_hat, y, cls))\n",
    "        print(\"Recall: \", recall(y_hat, y, cls))\n",
    "\n",
    "\n",
    "# Test case 3\n",
    "# Discrete Input and Discrete Output\n",
    "\n",
    "N = 30\n",
    "P = 5\n",
    "X = pd.DataFrame({i: pd.Series(np.random.randint(P, size=N), dtype=\"category\") for i in range(5)})\n",
    "y = pd.Series(np.random.randint(P, size=N), dtype=\"category\")\n",
    "\n",
    "for criteria in [\"information_gain\", \"gini_index\"]:\n",
    "    tree = DecisionTree(criterion=criteria)  # Split based on Inf. Gain\n",
    "    tree.fit(X, y)\n",
    "    y_hat = tree.predict(X)\n",
    "    tree.plot()\n",
    "    print(\"Criteria :\", criteria)\n",
    "    print(\"Accuracy: \", accuracy(y_hat, y))\n",
    "    for cls in y.unique():\n",
    "        print(\"Precision: \", precision(y_hat, y, cls))\n",
    "        print(\"Recall: \", recall(y_hat, y, cls))\n",
    "\n",
    "# Test case 4\n",
    "# Discrete Input and Real Output\n",
    "\n",
    "N = 30\n",
    "P = 5\n",
    "X = pd.DataFrame({i: pd.Series(np.random.randint(P, size=N), dtype=\"category\") for i in range(5)})\n",
    "y = pd.Series(np.random.randn(N))\n",
    "\n",
    "for criteria in [\"information_gain\", \"gini_index\"]:\n",
    "    tree = DecisionTree(criterion=criteria)  # Split based on Inf. Gain\n",
    "    tree.fit(X, y)\n",
    "    y_hat = tree.predict(X)\n",
    "    tree.plot()\n",
    "    print(\"Criteria :\", criteria)\n",
    "    print(\"RMSE: \", rmse(y_hat, y))\n",
    "    print(\"MAE: \", mae(y_hat, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c01f365",
   "metadata": {},
   "source": [
    "### 2. Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e10dd4",
   "metadata": {},
   "source": [
    "#### 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4a6924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done building\n",
      "?(X0 <= 0.043777523046321265)\n",
      "    Y: ?(X0 <= -0.17186200022530262)\n",
      "        Y: ?(X1 <= 1.3334978201484127)\n",
      "            Y: ?(X1 <= -1.0534230074515962)\n",
      "                Y: ?(X0 <= -0.23210583396758255)\n",
      "                    Y: Prediction: 1\n",
      "                    N: Prediction: None\n",
      "                N: ?(X1 <= -0.2335452640026076)\n",
      "                    Y: Prediction: None\n",
      "                    N: Prediction: None\n",
      "            N: Prediction: 1\n",
      "        N: ?(X0 <= -0.009944371488954856)\n",
      "            Y: ?(X0 <= -0.02217129486290728)\n",
      "                Y: ?(X0 <= -0.15154643493571088)\n",
      "                    Y: Prediction: 1\n",
      "                    N: Prediction: None\n",
      "                N: Prediction: 1\n",
      "            N: Prediction: None\n",
      "    N: Prediction: 1\n",
      "Criteria : gini_index\n",
      "Accuracy:  0.9\n",
      "Precision:  0.8947368421052632\n",
      "Recall:  0.9444444444444444\n",
      "Precision:  0.9090909090909091\n",
      "Recall:  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tree.base import DecisionTree\n",
    "from metrics import *\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Code given in the question\n",
    "X, y = make_classification(\n",
    "    n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=2, class_sep=0.5)\n",
    "\n",
    "# For plotting\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "# Write the code for Q2 a) and b) below. Show your results.\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y, dtype=\"category\")\n",
    "criteria = \"gini_index\"\n",
    "tree = DecisionTree(criterion=criteria)  # Split based on Inf. Gain\n",
    "train_data_size = int(0.7*(len(X)))\n",
    "\n",
    "X_train, y_train, X_test, y_test = X[:train_data_size], y[:train_data_size], X[train_data_size:], y[train_data_size:]\n",
    "tree.fit(X_train, y_train)\n",
    "y_hat = tree.predict(X_test)\n",
    "tree.plot()\n",
    "print(\"Criteria :\", criteria)\n",
    "# print(y_hat.shape, y_test.shape)\n",
    "print(\"Accuracy: \", accuracy(y_hat, y_test))\n",
    "for cls in y.unique():\n",
    "\n",
    "    print(\"Precision: \", precision(y_hat, y_test, cls))\n",
    "    print(\"Recall: \", recall(y_hat, y_test, cls))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad11b6",
   "metadata": {},
   "source": [
    "#### 2(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3fc9c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- cross validation --------------------------------------------------\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "done building\n",
      "2 0.9099999999999999\n"
     ]
    }
   ],
   "source": [
    "print(50*\"-\", \"cross validation\", 50*\"-\")\n",
    "\n",
    "K = 5\n",
    "fold_size = len(X)//K\n",
    "score = 0\n",
    "depths = [2,3,5,6,7]\n",
    "best_depth = None\n",
    "best_score = 0\n",
    "for depth in depths:\n",
    "    for i in range(K):\n",
    "        X_test_k = X[i*fold_size: (i+1)*fold_size]\n",
    "        y_test_k = y[i*fold_size: (i+1)*fold_size]\n",
    "        X_train_k = pd.concat([X[:i*fold_size], X[(i+1)*fold_size:]])\n",
    "        y_train_k = pd.concat([y[:i*fold_size], y[(i+1)*fold_size:]])\n",
    "        tree = DecisionTree(criterion=criteria, max_depth=depth)\n",
    "        tree.fit(X_train_k, y_train_k)\n",
    "        y_hat = tree.predict(X_test_k)\n",
    "        score += accuracy(y_hat, y_test_k) / K\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "    score = 0\n",
    "\n",
    "print(best_depth, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77a390",
   "metadata": {},
   "source": [
    "### 3. Auto Efficiency task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871afb41",
   "metadata": {},
   "source": [
    "#### 3(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "942b0e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done building\n",
      "(118,) (118,)\n",
      "RMSE:  11.57088889502843\n",
      "MAE:  9.30339753466872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tree.base import DecisionTree\n",
    "from metrics import *\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Reading the data\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "data = pd.read_csv(url, delim_whitespace=True, header=None,\n",
    "                 names=[\"mpg\", \"cylinders\", \"displacement\", \"horsepower\", \"weight\",\n",
    "                        \"acceleration\", \"model year\", \"origin\", \"car name\"])\n",
    "\n",
    "# Clean the above data by removing redundant columns and rows with junk values\n",
    "# Compare the performance of your model with the decision tree module from scikit learn\n",
    "\n",
    "data = data[~(data == '?').any(axis=1)].reset_index(drop = True)\n",
    "\n",
    "X = data.drop(columns = [\"mpg\",\"car name\"])\n",
    "y = data[\"mpg\"]\n",
    "\n",
    "X['horsepower'] = data[\"horsepower\"].astype(\"float\")\n",
    "\n",
    "criteria = \"entropy\"\n",
    "tree = DecisionTree(criterion=criteria)  # Split based on Inf. Gain\n",
    "train_data_size = int(0.7*(len(X)))\n",
    "\n",
    "X_train, y_train, X_test, y_test = X[:train_data_size], y[:train_data_size], X[train_data_size:], y[train_data_size:]\n",
    "tree.fit(X_train, y_train)\n",
    "y_hat = tree.predict(X_test)\n",
    "# tree.plot()\n",
    "print(y_hat.shape, y_test.shape)\n",
    "print(\"RMSE: \", rmse(y_hat, y))\n",
    "print(\"MAE: \", mae(y_hat, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa01c9",
   "metadata": {},
   "source": [
    "#### 3(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490dba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- sklearn --------------------------------------------------\n",
      "RMSE:  6.844898991342224\n",
      "MAE:  5.2853543913713406\n"
     ]
    }
   ],
   "source": [
    "print(50*\"-\", \"sklearn\", 50*\"-\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "model = DecisionTreeRegressor(criterion=\"squared_error\", max_depth=5)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, y_hat)))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c806c6",
   "metadata": {},
   "source": [
    "### Time complexity Analysis Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68713334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR\n",
      "Average time taken for fit:  9.374848008155823\n",
      "Average time taken for predict:  0.0015064477920532227\n",
      "Standard deviation for fit:  0.5732918977737427\n",
      "Standard deviation for predict:  0.0005081892013549805\n",
      "RD\n",
      "Average time taken for fit:  8.21259880065918\n",
      "Average time taken for predict:  0.0010169744491577148\n",
      "Standard deviation for fit:  3.2768430709838867\n",
      "Standard deviation for predict:  1.5497207641601562e-06\n",
      "DD\n",
      "Average time taken for fit:  0.4687316417694092\n",
      "Average time taken for predict:  0.0024993419647216797\n",
      "Standard deviation for fit:  0.06455516815185547\n",
      "Standard deviation for predict:  0.0014994144439697266\n",
      "DR\n",
      "Average time taken for fit:  1.3875056505203247\n",
      "Average time taken for predict:  0.0015064477920532227\n",
      "Standard deviation for fit:  0.29553544521331787\n",
      "Standard deviation for predict:  0.0004945993423461914\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 128\u001b[39m\n\u001b[32m    124\u001b[39m     plt.legend()\n\u001b[32m    125\u001b[39m     plt.show()\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m \u001b[43mplot_time_growth\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mplot_time_growth\u001b[39m\u001b[34m(N_values, M_values)\u001b[39m\n\u001b[32m     90\u001b[39m results_predict = {task: [] \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks}\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m N \u001b[38;5;129;01min\u001b[39;00m N_values:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     avg_fit, avg_predict = \u001b[43mtime_taken\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks:\n\u001b[32m     95\u001b[39m         results_fit[task].append(avg_fit[task])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtime_taken\u001b[39m\u001b[34m(N, M, P)\u001b[39m\n\u001b[32m     19\u001b[39m tree = DecisionTree(criterion=\u001b[33m\"\u001b[39m\u001b[33minformation_gain\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Split based on Inf. Gain\u001b[39;00m\n\u001b[32m     20\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m end = time.time()\n\u001b[32m     23\u001b[39m time_taken_for_fit[task].append(end - start)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\Desktop\\Masters\\Sem 1\\ML\\Assignments\\es335-25-fall-assignment-1\\tree\\base.py:73\u001b[39m, in \u001b[36mDecisionTree.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m     69\u001b[39m X = pd.get_dummies(X)\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# for col in X.columns:\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m#     print(col, X[col].dtype)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28mself\u001b[39m.root = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\Desktop\\Masters\\Sem 1\\ML\\Assignments\\es335-25-fall-assignment-1\\tree\\base.py:122\u001b[39m, in \u001b[36mDecisionTree.build\u001b[39m\u001b[34m(self, X, y, height)\u001b[39m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m(X_sub.shape[\u001b[32m0\u001b[39m] == \u001b[32m0\u001b[39m):\n\u001b[32m    121\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     node.children[key] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\Desktop\\Masters\\Sem 1\\ML\\Assignments\\es335-25-fall-assignment-1\\tree\\base.py:100\u001b[39m, in \u001b[36mDecisionTree.build\u001b[39m\u001b[34m(self, X, y, height)\u001b[39m\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Node(label=y.mode()[\u001b[32m0\u001b[39m], children={}, is_leaf=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     96\u001b[39m \u001b[38;5;66;03m# elif y.nunique() == 0:\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m#     return None\u001b[39;00m\n\u001b[32m     98\u001b[39m \n\u001b[32m     99\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     best_attr, max_gain, val_split = \u001b[43mopt_split_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m max_gain <= \u001b[32m0\u001b[39m:\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m check_ifreal(y):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\Desktop\\Masters\\Sem 1\\ML\\Assignments\\es335-25-fall-assignment-1\\tree\\utils.py:136\u001b[39m, in \u001b[36mopt_split_attribute\u001b[39m\u001b[34m(X, y, criterion, features)\u001b[39m\n\u001b[32m    133\u001b[39m splits = np.array(splits)\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m splits:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m     gain = \u001b[43minformation_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mftr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gain > max_gain:\n\u001b[32m    138\u001b[39m         max_gain = gain\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\Desktop\\Masters\\Sem 1\\ML\\Assignments\\es335-25-fall-assignment-1\\tree\\utils.py:75\u001b[39m, in \u001b[36minformation_gain\u001b[39m\u001b[34m(Y, attr, criterion, val)\u001b[39m\n\u001b[32m     73\u001b[39m         before_split += entropy(Y)\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         before_split += \u001b[43mgini_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_ifreal(attr): \u001b[38;5;66;03m#for discrete input.\u001b[39;00m\n\u001b[32m     78\u001b[39m     temp = Y.groupby(attr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\Desktop\\Masters\\Sem 1\\ML\\Assignments\\es335-25-fall-assignment-1\\tree\\utils.py:44\u001b[39m, in \u001b[36mgini_index\u001b[39m\u001b[34m(Y)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgini_index\u001b[39m(Y: pd.Series) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     41\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    Function to calculate the gini index\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     class_count = \u001b[43mY\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m# print(class_count)\u001b[39;00m\n\u001b[32m     46\u001b[39m     num_data = Y.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:980\u001b[39m, in \u001b[36mIndexOpsMixin.value_counts\u001b[39m\u001b[34m(self, normalize, sort, ascending, bins, dropna)\u001b[39m\n\u001b[32m    894\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalue_counts\u001b[39m(\n\u001b[32m    895\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    896\u001b[39m     normalize: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    900\u001b[39m     dropna: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    901\u001b[39m ) -> Series:\n\u001b[32m    902\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    903\u001b[39m \u001b[33;03m    Return a Series containing counts of unique values.\u001b[39;00m\n\u001b[32m    904\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    978\u001b[39m \u001b[33;03m    dtype: int64\u001b[39;00m\n\u001b[32m    979\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\algorithms.py:1001\u001b[39m, in \u001b[36mvalue_counts\u001b[39m\u001b[34m(values, sort, ascending, normalize, bins, dropna)\u001b[39m\n\u001b[32m    998\u001b[39m         result = Series(counts, index=idx, name=name)\n\u001b[32m   1000\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort:\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m     result = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[32m   1004\u001b[39m     result = result / counts.sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    326\u001b[39m     warnings.warn(\n\u001b[32m    327\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    328\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    329\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    330\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:3768\u001b[39m, in \u001b[36mSeries.sort_values\u001b[39m\u001b[34m(self, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   3766\u001b[39m \u001b[38;5;66;03m# GH 35922. Make sorting stable by leveraging nargsort\u001b[39;00m\n\u001b[32m   3767\u001b[39m values_to_sort = ensure_key_mapped(\u001b[38;5;28mself\u001b[39m, key)._values \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values\n\u001b[32m-> \u001b[39m\u001b[32m3768\u001b[39m sorted_index = \u001b[43mnargsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues_to_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3770\u001b[39m result = \u001b[38;5;28mself\u001b[39m._constructor(\n\u001b[32m   3771\u001b[39m     \u001b[38;5;28mself\u001b[39m._values[sorted_index], index=\u001b[38;5;28mself\u001b[39m.index[sorted_index]\n\u001b[32m   3772\u001b[39m )\n\u001b[32m   3774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\karti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\sorting.py:438\u001b[39m, in \u001b[36mnargsort\u001b[39m\u001b[34m(items, kind, ascending, na_position, key, mask)\u001b[39m\n\u001b[32m    436\u001b[39m     non_nans = non_nans[::-\u001b[32m1\u001b[39m]\n\u001b[32m    437\u001b[39m     non_nan_idx = non_nan_idx[::-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m indexer = non_nan_idx[\u001b[43mnon_nans\u001b[49m\u001b[43m.\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ascending:\n\u001b[32m    440\u001b[39m     indexer = indexer[::-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tree.base import DecisionTree\n",
    "from metrics import *\n",
    "import time\n",
    "\n",
    "def time_taken(N = 30, M = 5, P = 2):\n",
    "    tasks = [\"DD\", \"DR\"]\n",
    "    time_taken_for_fit = {x: [] for x in tasks}\n",
    "    time_taken_for_predict = {x: [] for x in tasks}\n",
    "    num_average_time = 2\n",
    "    for i in range(num_average_time):\n",
    "        for task in tasks:\n",
    "            if task == \"RR\":\n",
    "                X = pd.DataFrame({i: pd.Series(np.random.randn(N), dtype=\"category\") for i in range(M)})\n",
    "                y = pd.Series(np.random.randn(N), dtype=\"category\")\n",
    "                tree = DecisionTree(criterion=\"information_gain\")  # Split based on Inf. Gain\n",
    "                start = time.time()\n",
    "                tree.fit(X, y)\n",
    "                end = time.time()\n",
    "                time_taken_for_fit[task].append(end - start)\n",
    "                start = time.time()\n",
    "                y_hat = tree.predict(X)\n",
    "                end = time.time()\n",
    "                time_taken_for_predict[task].append(end - start)\n",
    "            elif task == \"RD\":\n",
    "                X = pd.DataFrame({i: pd.Series(np.random.randn(N), dtype=\"category\") for i in range(M)})\n",
    "                y = pd.Series(np.random.randint(P, size=N), dtype=\"category\")\n",
    "                tree = DecisionTree(criterion=\"information_gain\")  # Split based on Inf. Gain\n",
    "                start = time.time()\n",
    "                tree.fit(X, y)\n",
    "                end = time.time()\n",
    "                time_taken_for_fit[task].append(end - start)\n",
    "                start = time.time()\n",
    "                y_hat = tree.predict(X)\n",
    "                end = time.time()\n",
    "                time_taken_for_predict[task].append(end - start)\n",
    "            elif task == \"DD\":\n",
    "\n",
    "                X = pd.DataFrame({i: pd.Series(np.random.randint(P, size=N), dtype=\"category\") for i in range(M)})\n",
    "                y = pd.Series(np.random.randint(P, size=N), dtype=\"category\")\n",
    "                tree = DecisionTree(criterion=\"information_gain\")  # Split based on Inf. Gain\n",
    "                start = time.time()\n",
    "                tree.fit(X, y)\n",
    "                end = time.time()\n",
    "                time_taken_for_fit[task].append(end - start)\n",
    "                start = time.time()\n",
    "                y_hat = tree.predict(X)\n",
    "                end = time.time()\n",
    "                time_taken_for_predict[task].append(end - start)\n",
    "            elif task == \"DR\":\n",
    "                X = pd.DataFrame({i: pd.Series(np.random.randint(P, size=N), dtype=\"category\") for i in range(M)})\n",
    "                y = pd.Series(np.random.randn(N), dtype=\"category\")\n",
    "                tree = DecisionTree(criterion=\"information_gain\")  # Split based on Inf. Gain\n",
    "                start = time.time()\n",
    "                tree.fit(X, y)\n",
    "                end = time.time()\n",
    "                time_taken_for_fit[task].append(end - start)\n",
    "                start = time.time()\n",
    "                y_hat = tree.predict(X)\n",
    "                end = time.time()\n",
    "                time_taken_for_predict[task].append(end - start)\n",
    "\n",
    "    # Function to calculate average time (and std) taken by fit() and predict() for different N and P for 4 different cases of DTs\n",
    "    avg_fit_time = {}\n",
    "    avg_predict_time = {}\n",
    "    for task in tasks:\n",
    "        avg_fit_time[task] = np.mean(time_taken_for_fit[task])\n",
    "        avg_predict_time[task] = np.mean(time_taken_for_predict[task])\n",
    "        print(task)\n",
    "        print(\"Average time taken for fit: \", np.mean(time_taken_for_fit[task]))\n",
    "        print(\"Average time taken for predict: \", np.mean(time_taken_for_predict[task]))\n",
    "        print(\"Standard deviation for fit: \", np.std(time_taken_for_fit[task]))\n",
    "        print(\"Standard deviation for predict: \", np.std(time_taken_for_predict[task]))\n",
    "    \n",
    "\n",
    "    return avg_fit_time, avg_predict_time\n",
    "\n",
    "def plot_time_growth(N_values=None, M_values=None):\n",
    "    if N_values is None:\n",
    "        N_values = [16, 32, 48, 64, 128]\n",
    "    if M_values is None:\n",
    "        M_values = [2, 4, 8, 16, 32]\n",
    "\n",
    "    tasks = [\"DD\", \"DR\"]\n",
    "\n",
    "    results_fit = {task: [] for task in tasks}\n",
    "    results_predict = {task: [] for task in tasks}\n",
    "\n",
    "    for N in N_values:\n",
    "        avg_fit, avg_predict = time_taken(N=N, M=5)\n",
    "        for task in tasks:\n",
    "            results_fit[task].append(avg_fit[task])\n",
    "            results_predict[task].append(avg_predict[task])\n",
    "    \n",
    "    for task in tasks:\n",
    "        plt.plot(N_values, results_fit[task], label=f\"{task} - fit\")\n",
    "        plt.plot(N_values, results_predict[task], linestyle=\"--\", label=f\"{task} - predict\")\n",
    "\n",
    "    plt.xlabel(\"N (sample size)\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.title(\"Growth of Decision Tree Time vs N\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    results_fit = {task: [] for task in tasks}\n",
    "    results_predict = {task: [] for task in tasks}\n",
    "\n",
    "    for P in M_values:\n",
    "        avg_fit, avg_predict = time_taken(N=32, M=M)\n",
    "        for task in tasks:\n",
    "            results_fit[task].append(avg_fit[task])\n",
    "            results_predict[task].append(avg_predict[task])\n",
    "\n",
    "    for task in tasks:\n",
    "        plt.plot(M_values, results_fit[task], label=f\"{task} - fit\")\n",
    "        plt.plot(M_values, results_predict[task], linestyle=\"--\", label=f\"{task} - predict\")\n",
    "\n",
    "    plt.xlabel(\"P (number of categories)\")\n",
    "    plt.ylabel(\"Time (seconds)\")\n",
    "    plt.title(\"Growth of Decision Tree Time vs P\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_time_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dd8c7d",
   "metadata": {},
   "source": [
    "### Theoretical Time complexity comes out to be $O(N^2Mlog(N))$, where $N, M$ are number of samples and number of features respectiverly. The time grows quadraticaly as N increases and linearly as M increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d3966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
